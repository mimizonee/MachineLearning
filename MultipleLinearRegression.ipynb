{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultipleLinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimizonee/MachineLearning/blob/main/MultipleLinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xw-kf6jaJZ7"
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ChfL0PsNl_"
      },
      "source": [
        "Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVSyubgsQyF"
      },
      "source": [
        "from sklearn.datasets import load_boston"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV0khiabsbD6"
      },
      "source": [
        "boston = load_boston()\n",
        "#print(boston)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEgiDxUqtAPU",
        "outputId": "63510751-7bab-48f6-8f0d-01bb776100ef"
      },
      "source": [
        "boston['feature_names']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orEDpspqui1n",
        "outputId": "627c4cdd-642e-4a2a-c32f-0f8df77727ab"
      },
      "source": [
        "boston['data'].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqyiQUljumi1"
      },
      "source": [
        "bost = pd.DataFrame(boston['data'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "S97Rp-KzupvZ",
        "outputId": "021f9256-d1e9-4c42-a3e9-5b3df1004c6b"
      },
      "source": [
        "bost.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1     2    3      4   ...   8      9     10      11    12\n",
              "0  0.00632  18.0  2.31  0.0  0.538  ...  1.0  296.0  15.3  396.90  4.98\n",
              "1  0.02731   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  396.90  9.14\n",
              "2  0.02729   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  392.83  4.03\n",
              "3  0.03237   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  394.63  2.94\n",
              "4  0.06905   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  396.90  5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v62pI_Tuvk9"
      },
      "source": [
        "bost.columns = boston['feature_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sg1-Lopru554",
        "outputId": "30030412-616f-4b74-8406-504b469d8e4a"
      },
      "source": [
        "bost.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJYks99Iu_R7",
        "outputId": "3844781c-1d31-49af-ae62-5128df887921"
      },
      "source": [
        "boston['target']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMyUC2KQvLC7"
      },
      "source": [
        "Normalizing input matrix to keep tha data in the range of -1 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfsrkmRAvGjw"
      },
      "source": [
        "X = (bost - bost.mean())/(bost.max()-bost.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "zo2R_hoXwTCU",
        "outputId": "d793942c-b2be-4006-d231-ea4e9e5564e4"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-3.208896e-18</td>\n",
              "      <td>1.148072e-16</td>\n",
              "      <td>-6.812595e-16</td>\n",
              "      <td>-1.189760e-16</td>\n",
              "      <td>6.223338e-16</td>\n",
              "      <td>-1.521044e-15</td>\n",
              "      <td>-3.491388e-16</td>\n",
              "      <td>1.206490e-16</td>\n",
              "      <td>6.406821e-17</td>\n",
              "      <td>1.933017e-16</td>\n",
              "      <td>-2.300312e-15</td>\n",
              "      <td>1.881620e-15</td>\n",
              "      <td>-1.082797e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.667929e-02</td>\n",
              "      <td>2.332245e-01</td>\n",
              "      <td>2.514792e-01</td>\n",
              "      <td>2.539940e-01</td>\n",
              "      <td>2.384314e-01</td>\n",
              "      <td>1.346268e-01</td>\n",
              "      <td>2.898956e-01</td>\n",
              "      <td>1.914822e-01</td>\n",
              "      <td>3.785765e-01</td>\n",
              "      <td>3.216357e-01</td>\n",
              "      <td>2.303134e-01</td>\n",
              "      <td>2.302054e-01</td>\n",
              "      <td>1.970492e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.054410e-02</td>\n",
              "      <td>-1.136364e-01</td>\n",
              "      <td>-3.913775e-01</td>\n",
              "      <td>-6.916996e-02</td>\n",
              "      <td>-3.491668e-01</td>\n",
              "      <td>-5.218690e-01</td>\n",
              "      <td>-6.763636e-01</td>\n",
              "      <td>-2.423813e-01</td>\n",
              "      <td>-3.717134e-01</td>\n",
              "      <td>-4.222083e-01</td>\n",
              "      <td>-6.229291e-01</td>\n",
              "      <td>-8.985678e-01</td>\n",
              "      <td>-3.014090e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-3.969297e-02</td>\n",
              "      <td>-1.136364e-01</td>\n",
              "      <td>-2.179904e-01</td>\n",
              "      <td>-6.916996e-02</td>\n",
              "      <td>-2.174795e-01</td>\n",
              "      <td>-7.647718e-02</td>\n",
              "      <td>-2.425325e-01</td>\n",
              "      <td>-1.541223e-01</td>\n",
              "      <td>-2.412786e-01</td>\n",
              "      <td>-2.466358e-01</td>\n",
              "      <td>-1.122908e-01</td>\n",
              "      <td>4.716191e-02</td>\n",
              "      <td>-1.573693e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.773202e-02</td>\n",
              "      <td>-1.136364e-01</td>\n",
              "      <td>-5.303441e-02</td>\n",
              "      <td>-6.916996e-02</td>\n",
              "      <td>-3.435197e-02</td>\n",
              "      <td>-1.458793e-02</td>\n",
              "      <td>9.191657e-02</td>\n",
              "      <td>-5.343258e-02</td>\n",
              "      <td>-1.978003e-01</td>\n",
              "      <td>-1.493075e-01</td>\n",
              "      <td>6.324111e-02</td>\n",
              "      <td>8.766445e-02</td>\n",
              "      <td>-3.568055e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.143872e-04</td>\n",
              "      <td>1.136364e-02</td>\n",
              "      <td>2.552500e-01</td>\n",
              "      <td>-6.916996e-02</td>\n",
              "      <td>1.426028e-01</td>\n",
              "      <td>6.492922e-02</td>\n",
              "      <td>2.626169e-01</td>\n",
              "      <td>1.267068e-01</td>\n",
              "      <td>6.282866e-01</td>\n",
              "      <td>4.919138e-01</td>\n",
              "      <td>1.855815e-01</td>\n",
              "      <td>9.973011e-02</td>\n",
              "      <td>1.187069e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.594559e-01</td>\n",
              "      <td>8.863636e-01</td>\n",
              "      <td>6.086225e-01</td>\n",
              "      <td>9.308300e-01</td>\n",
              "      <td>6.508332e-01</td>\n",
              "      <td>4.781310e-01</td>\n",
              "      <td>3.236364e-01</td>\n",
              "      <td>7.576187e-01</td>\n",
              "      <td>6.282866e-01</td>\n",
              "      <td>5.777917e-01</td>\n",
              "      <td>3.770709e-01</td>\n",
              "      <td>1.014322e-01</td>\n",
              "      <td>6.985910e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               CRIM            ZN  ...             B         LSTAT\n",
              "count  5.060000e+02  5.060000e+02  ...  5.060000e+02  5.060000e+02\n",
              "mean  -3.208896e-18  1.148072e-16  ...  1.881620e-15 -1.082797e-16\n",
              "std    9.667929e-02  2.332245e-01  ...  2.302054e-01  1.970492e-01\n",
              "min   -4.054410e-02 -1.136364e-01  ... -8.985678e-01 -3.014090e-01\n",
              "25%   -3.969297e-02 -1.136364e-01  ...  4.716191e-02 -1.573693e-01\n",
              "50%   -3.773202e-02 -1.136364e-01  ...  8.766445e-02 -3.568055e-02\n",
              "75%    7.143872e-04  1.136364e-02  ...  9.973011e-02  1.187069e-01\n",
              "max    9.594559e-01  8.863636e-01  ...  1.014322e-01  6.985910e-01\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK93GY2lwb4o"
      },
      "source": [
        "Y = boston['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBglRV3vwl3m",
        "outputId": "8a99d27d-50dc-4d8c-d643-c8f46d11706c"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsqmBi_5w3OH"
      },
      "source": [
        "Splitting the data into training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjZ1Iuc6wrB1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6HJvnahxGLU"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwPfc_Bax5vR",
        "outputId": "f67c3060-f502-4d95-f87c-ddf6ce443ea3"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(339, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTbSX1Bnx89d"
      },
      "source": [
        "X_train = X_train.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Uvzna1x-Oe",
        "outputId": "edfb1b7b-f5ae-4531-a7dc-05fe95c6a4de"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 339)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATzXfyUIymnh",
        "outputId": "21939dd9-e3a2-4cae-9909-f10e53260ea9"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(339,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d0fUXtDywTh"
      },
      "source": [
        "Y_train = np.array([Y_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f7Wnnh5y32C",
        "outputId": "c18fdeca-ab07-4e50-d71d-728a526b8101"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 339)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-GWdEw-zKbK"
      },
      "source": [
        "X_test = X_test.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nji5hYTTzVl0",
        "outputId": "ac423c0d-895a-442e-f086-7d3bbea86288"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 167)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFxACmf2zcP0"
      },
      "source": [
        "Y_test = np.array([Y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DYr3AkKzp1Y",
        "outputId": "aa257cd3-efbf-4b4a-8150-eb47516adad8"
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 167)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv-wHZmbTRt9"
      },
      "source": [
        "Initialization of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etR0Q_Z8VkJ0"
      },
      "source": [
        "def initialize(lenw):\n",
        "  #w = np.random.randn(1, lenw)\n",
        "  w = np.zeros((1,lenw))\n",
        "  b = 0\n",
        "  return w, b\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqwdT8HKVGWP"
      },
      "source": [
        "Forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XoMGwWxVF6T"
      },
      "source": [
        "def f_prop(X, w, b):\n",
        "  Z = np.dot(w, X) + b\n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCTdd89fXzX6"
      },
      "source": [
        "Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdxN5iPxX34R"
      },
      "source": [
        "def cost_function(Z, Y):\n",
        "  m = len(Y)\n",
        "  J = (0.5/m)*np.sum(np.square(Z-Y))\n",
        "  return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywMi6LqFb4Ve"
      },
      "source": [
        "Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_jcl5jCb-nO"
      },
      "source": [
        "def b_prop(X, Y, Z):\n",
        "  m = len(Y)\n",
        "  dz = (1/m)*(Z-Y)\n",
        "  dw = np.dot(dz, X.T)\n",
        "  db = np.sum(dz)\n",
        "  return dw, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcKbvKH2c7An"
      },
      "source": [
        "Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds0xXhZ4c9-I"
      },
      "source": [
        "def update(w, b, dw, db, lr):\n",
        "  w = w - (lr*dw)\n",
        "  b = b - (lr*db)\n",
        "  return w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuJZ4GMxcsKW"
      },
      "source": [
        "# Constructing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax39aR-Oc0Q8"
      },
      "source": [
        "def mul_linear_regression(X_train, Y_train, X_test, Y_test, lr, epoch):\n",
        "  lenw = len(X_train)\n",
        "  w, b = initialize(lenw)\n",
        "\n",
        "  cost_train = []\n",
        "  m_train = len(Y_train)\n",
        "  m_test = len(Y_test)\n",
        "  for i in range(1, epoch+1):\n",
        "    Z_train = f_prop(X_train, w, b)\n",
        "    cost = cost_function(Z_train, Y_train)\n",
        "    dw, db = b_prop(X_train, Y_train, Z_train)\n",
        "    w, b = update(w, b, dw, db, lr)\n",
        "\n",
        "    if i%10==0:\n",
        "      cost_train.append(cost)\n",
        "\n",
        "    MAE_train = (1/m_train)*np.sum(np.abs(Z_train - Y_train))\n",
        "\n",
        "    Z_test = f_prop(X_test, w, b)\n",
        "    cost_test = cost_function(Z_test, Y_test)\n",
        "    MAE_test = (1/m_test)*np.sum(np.abs(Z_test - Y_test))\n",
        "\n",
        "    print('Epochs '+str(i)+'/'+str(epoch)+': ')\n",
        "    print('Training cost '+str(cost_train)+'|'+'Validation cost '+str(cost_test))\n",
        "    print('MAE cost '+str(MAE_train)+'|'+'Validation cost '+str(MAE_test))\n",
        "\n",
        "  plt.plot(cost_train)  \n",
        "  plt.xlabel('Iterations per tens')\n",
        "  plt.ylabel('Training cost')\n",
        "  plt.title('Learning rate '+str(lr))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIgsIRar0B79"
      },
      "source": [
        "#Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2G75sOr80IJ7",
        "outputId": "3165ddfa-9ce2-48fb-c05a-acf916b6e669"
      },
      "source": [
        "mul_linear_regression(X_train, Y_train, X_test, Y_test, 0.04, 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 1/500: \n",
            "Training cost []|Validation cost 6695409.959647618\n",
            "MAE cost 7640.1|Validation cost 47059.286579447435\n",
            "Epochs 2/500: \n",
            "Training cost []|Validation cost 1058402258.616247\n",
            "MAE cost 96174.73742055261|Validation cost 594041.6908042508\n",
            "Epochs 3/500: \n",
            "Training cost []|Validation cost 167297809504.90704\n",
            "MAE cost 1209300.9705877346|Validation cost 7473028.865908602\n",
            "Epochs 4/500: \n",
            "Training cost []|Validation cost 26434916187411.914\n",
            "MAE cost 15199880.117395163|Validation cost 93950511.92360085\n",
            "Epochs 5/500: \n",
            "Training cost []|Validation cost 4175404413107747.5\n",
            "MAE cost 191022152.66917348|Validation cost 1180798407.9354544\n",
            "Epochs 6/500: \n",
            "Training cost []|Validation cost 6.594084670654464e+17\n",
            "MAE cost 2400517297.495843|Validation cost 14839149931.903606\n",
            "Epochs 7/500: \n",
            "Training cost []|Validation cost 1.0413232216919879e+20\n",
            "MAE cost 30166004463.98096|Validation cost 186477470397.2346\n",
            "Epochs 8/500: \n",
            "Training cost []|Validation cost 1.6443998457854706e+22\n",
            "MAE cost 379077305557.85547|Validation cost 2343354314559.457\n",
            "Epochs 9/500: \n",
            "Training cost []|Validation cost 2.5967249871303673e+24\n",
            "MAE cost 4763615573976.449|Validation cost 29447434115955.125\n",
            "Epochs 10/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 4.1005609463348024e+26\n",
            "MAE cost 59861175212792.31|Validation cost 370046414892441.7\n",
            "Epochs 11/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 6.47530372886196e+28\n",
            "MAE cost 752235162085727.2|Validation cost 4650125439261836.0\n",
            "Epochs 12/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 1.0225318797665963e+31\n",
            "MAE cost 9452832664375114.0|Validation cost 5.843499833053573e+16\n",
            "Epochs 13/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 1.6147061962024337e+33\n",
            "MAE cost 1.1878737669277962e+17|Validation cost 7.343132545848911e+17\n",
            "Epochs 14/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 2.5498236536013157e+35\n",
            "MAE cost 1.492720874653653e+18|Validation cost 9.227619662471283e+18\n",
            "Epochs 15/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 4.0264913613176823e+37\n",
            "MAE cost 1.8758016711280116e+19|Validation cost 1.1595727459722237e+20\n",
            "Epochs 16/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 6.358334842647142e+39\n",
            "MAE cost 2.357193472653358e+20|Validation cost 1.4571568801499835e+21\n",
            "Epochs 17/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 1.0040608124986395e+42\n",
            "MAE cost 2.962126086637855e+21|Validation cost 1.8311107929044033e+22\n",
            "Epochs 18/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 1.5855379423981582e+44\n",
            "MAE cost 3.7223041097718315e+22|Validation cost 2.3010334575592303e+23\n",
            "Epochs 19/500: \n",
            "Training cost [5.286062074299099e+24]|Validation cost 2.5037632529074757e+46\n",
            "MAE cost 4.6775685703513334e+23|Validation cost 2.891553581749414e+24\n",
            "Epochs 20/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 3.953756172138991e+48\n",
            "MAE cost 5.877985001850629e+24|Validation cost 3.6336204013397845e+25\n",
            "Epochs 21/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 6.24347683430052e+50\n",
            "MAE cost 7.386467384045885e+25|Validation cost 4.566125733943747e+26\n",
            "Epochs 22/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 9.859232912380592e+52\n",
            "MAE cost 9.282075472826561e+26|Validation cost 5.737942304129234e+27\n",
            "Epochs 23/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 1.5568965209582037e+55\n",
            "MAE cost 1.1664158332194697e+28|Validation cost 7.210485169222764e+28\n",
            "Epochs 24/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 2.458534856117772e+57\n",
            "MAE cost 1.465756123150691e+29|Validation cost 9.060930490378898e+29\n",
            "Epochs 25/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 3.882334861293013e+59\n",
            "MAE cost 1.8419168802118122e+30|Validation cost 1.13862603451263e+31\n",
            "Epochs 26/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 6.130693627426537e+61\n",
            "MAE cost 2.3146127381111074e+31|Validation cost 1.4308345570539089e+32\n",
            "Epochs 27/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 9.681134084566602e+63\n",
            "MAE cost 2.908617747620599e+32|Validation cost 1.798033302949942e+33\n",
            "Epochs 28/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 1.5287724825142898e+66\n",
            "MAE cost 3.6550637877666997e+33|Validation cost 2.259467205749913e+34\n",
            "Epochs 29/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46]|Validation cost 2.414123472392238e+68\n",
            "MAE cost 4.593072191618223e+34|Validation cost 2.8393200757090842e+35\n",
            "Epochs 30/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 3.8122037167820726e+70\n",
            "MAE cost 5.771804100389385e+35|Validation cost 3.567982076397936e+36\n",
            "Epochs 31/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 6.019947755135274e+72\n",
            "MAE cost 7.253037005180332e+36|Validation cost 4.483642477087628e+37\n",
            "Epochs 32/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 9.506252463640273e+74\n",
            "MAE cost 9.114402513239536e+37|Validation cost 5.634291157269365e+38\n",
            "Epochs 33/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 1.5011564813893662e+77\n",
            "MAE cost 1.145345503049474e+39|Validation cost 7.08023376241721e+39\n",
            "Epochs 34/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 2.3705143433087086e+79\n",
            "MAE cost 1.439278460052773e+40|Validation cost 8.897252330631725e+40\n",
            "Epochs 35/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 3.7433394329626768e+81\n",
            "MAE cost 1.8086441864541908e+41|Validation cost 1.1180577039013724e+42\n",
            "Epochs 36/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 5.911202414753115e+83\n",
            "MAE cost 2.2728011875301736e+42|Validation cost 1.404987722950702e+43\n",
            "Epochs 37/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 9.334529933484518e+85\n",
            "MAE cost 2.8560759914672147e+43|Validation cost 1.7655533294517068e+44\n",
            "Epochs 38/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 1.4740393403151236e+88\n",
            "MAE cost 3.589038105836144e+44|Validation cost 2.2186518132638386e+45\n",
            "Epochs 39/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68]|Validation cost 2.327692976806981e+90\n",
            "MAE cost 4.510102169419733e+45|Validation cost 2.788030124260011e+46\n",
            "Epochs 40/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 3.6757191250528225e+92\n",
            "MAE cost 5.66754126837717e+46|Validation cost 3.5035294530268547e+47\n",
            "Epochs 41/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 5.804421468338452e+94\n",
            "MAE cost 7.122016934904821e+47|Validation cost 4.402649211505404e+48\n",
            "Epochs 42/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 9.165909427756986e+96\n",
            "MAE cost 8.949758425948787e+48|Validation cost 5.532512381998969e+49\n",
            "Epochs 43/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 1.447412047800414e+99\n",
            "MAE cost 1.1246557908375958e+50|Validation cost 6.95233523874273e+50\n",
            "Epochs 44/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 2.2856451426123898e+101\n",
            "MAE cost 1.413279093877272e+51|Validation cost 8.736530880460473e+51\n",
            "Epochs 45/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 3.609320321664186e+103\n",
            "MAE cost 1.7759725361863965e+52|Validation cost 1.0978609230449382e+53\n",
            "Epochs 46/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 5.699569430750995e+105\n",
            "MAE cost 2.2317449277730837e+53|Validation cost 1.3796077903699424e+54\n",
            "Epochs 47/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 9.000334910970991e+107\n",
            "MAE cost 2.804483358360977e+54|Validation cost 1.7336600796124036e+55\n",
            "Epochs 48/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 1.4212657551391483e+110\n",
            "MAE cost 3.524205122837122e+55|Validation cost 2.1785737168356665e+56\n",
            "Epochs 49/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90]|Validation cost 2.2443568675083104e+112\n",
            "MAE cost 4.428630931541716e+56|Validation cost 2.7376666830491243e+57\n",
            "Epochs 50/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 3.544120957335355e+114\n",
            "MAE cost 5.565161857553571e+57|Validation cost 3.44024111259511e+58\n",
            "Epochs 51/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 5.596611457859946e+116\n",
            "MAE cost 6.993363633033048e+58|Validation cost 4.323119021782413e+59\n",
            "Epochs 52/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 8.837751359874217e+118\n",
            "MAE cost 8.788088496913662e+59|Validation cost 5.43257215550186e+60\n",
            "Epochs 53/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 1.3955917734697452e+121\n",
            "MAE cost 1.1043398210381785e+61|Validation cost 6.826747095333509e+61\n",
            "Epochs 54/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 2.2038144306926383e+123\n",
            "MAE cost 1.3877493845890862e+62|Validation cost 8.578712729373621e+62\n",
            "Epochs 55/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 3.480099365199077e+125\n",
            "MAE cost 1.7438910720587045e+63|Validation cost 1.078028980206739e+64\n",
            "Epochs 56/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 5.495513334964699e+127\n",
            "MAE cost 2.191430315140473e+64|Validation cost 1.3546863251247208e+65\n",
            "Epochs 57/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 8.678104745163561e+129\n",
            "MAE cost 2.753822703184876e+65|Validation cost 1.7023429547580256e+66\n",
            "Epochs 58/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 1.3703815708876648e+132\n",
            "MAE cost 3.460543293657204e+66|Validation cost 2.1392195978264417e+67\n",
            "Epochs 59/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112]|Validation cost 2.164004359218125e+134\n",
            "MAE cost 4.348631403694216e+67|Validation cost 2.6882130154409463e+68\n",
            "Epochs 60/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 3.417234269782019e+136\n",
            "MAE cost 5.464631845484082e+68|Validation cost 3.378096023301485e+69\n",
            "Epochs 61/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 5.396241465424696e+138\n",
            "MAE cost 6.867034345865793e+69|Validation cost 4.2450254786722984e+70\n",
            "Epochs 62/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 8.521342013530248e+140\n",
            "MAE cost 8.629339000443339e+70|Validation cost 5.334437265926329e+71\n",
            "Epochs 63/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 1.3456267696101137e+143\n",
            "MAE cost 1.0843908423059426e+72|Validation cost 6.703427597095065e+72\n",
            "Epochs 64/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 2.1249134235150861e+145\n",
            "MAE cost 1.362680848227864e+73|Validation cost 8.423745431692232e+73\n",
            "Epochs 65/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 3.355504779934534e+147\n",
            "MAE cost 1.7123891328502368e+74|Validation cost 1.0585552848919571e+75\n",
            "Epochs 66/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 5.298762859494715e+149\n",
            "MAE cost 2.151843952394976e+75|Validation cost 1.3302150453846151e+76\n",
            "Epochs 67/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 8.367411070029351e+151\n",
            "MAE cost 2.7040771905341238e+76|Validation cost 1.6715915476707452e+77\n",
            "Epochs 68/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 1.3213191431919664e+154\n",
            "MAE cost 3.398031462378448e+77|Validation cost 2.1005763781873057e+78\n",
            "Epochs 69/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134]|Validation cost 2.0865286329949946e+156\n",
            "MAE cost 4.270077000661754e+78|Validation cost 2.6396526871333627e+79\n",
            "Epochs 70/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 3.2948903818881956e+158\n",
            "MAE cost 5.365917824321122e+79|Validation cost 3.317073533266724e+80\n",
            "Epochs 71/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 5.203045123361783e+160\n",
            "MAE cost 6.742987092013779e+80|Validation cost 4.168342630351006e+81\n",
            "Epochs 72/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 8.216260760767686e+162\n",
            "MAE cost 8.473457181356832e+81|Validation cost 5.2380751013650886e+82\n",
            "Epochs 73/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 1.297450613791973e+165\n",
            "MAE cost 1.0648022252530355e+83|Validation cost 6.582335762842615e+83\n",
            "Epochs 74/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 2.0488372317334793e+167\n",
            "MAE cost 1.3380651540889278e+84|Validation cost 8.271577489124858e+84\n",
            "Epochs 75/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 3.2353709324387056e+169\n",
            "MAE cost 1.6814562499261852e+85|Validation cost 1.039433365657573e+86\n",
            "Epochs 76/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 5.109056448380169e+171\n",
            "MAE cost 2.1129726843091584e+86|Validation cost 1.3061858189235679e+87\n",
            "Epochs 77/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 8.067840855904544e+173\n",
            "MAE cost 2.655230289121496e+87|Validation cost 1.6413956391304544e+88\n",
            "Epochs 78/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 1.2740132494883554e+176\n",
            "MAE cost 3.336648855246947e+88|Validation cost 2.062631216113459e+89\n",
            "Epochs 79/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156]|Validation cost 2.011826694231317e+178\n",
            "MAE cost 4.192941617468623e+89|Validation cost 2.591969560696239e+90\n",
            "Epochs 80/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 3.17692665225198e+180\n",
            "MAE cost 5.268986989702047e+90|Validation cost 3.2571533636705622e+91\n",
            "Epochs 81/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 5.0167656005008286e+182\n",
            "MAE cost 6.621180648446551e+91|Validation cost 4.093044993792564e+92\n",
            "Epochs 82/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 7.922102032959438e+184\n",
            "MAE cost 8.320391237451544e+92|Validation cost 5.143453639017787e+93\n",
            "Epochs 83/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 1.250999261642895e+187\n",
            "MAE cost 1.0455674602459727e+94|Validation cost 6.4634313516823404e+94\n",
            "Epochs 84/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 1.9754847212519879e+189\n",
            "MAE cost 1.3138941219548396e+95|Validation cost 8.122158333653786e+95\n",
            "Epochs 85/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 3.1195381192911083e+191\n",
            "MAE cost 1.6510821437589096e+96|Validation cost 1.0206568679617943e+97\n",
            "Epochs 86/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 4.926141909891786e+193\n",
            "MAE cost 2.0748035932938097e+97|Validation cost 1.282590660417412e+98\n",
            "Epochs 87/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 7.7789958604214e+195\n",
            "MAE cost 2.6072657662836982e+98|Validation cost 1.6117451945187432e+99\n",
            "Epochs 88/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 1.2284010023126307e+198\n",
            "MAE cost 3.276375073769351e+99|Validation cost 2.025371501776605e+100\n",
            "Epochs 89/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178]|Validation cost 1.9397992357344343e+200\n",
            "MAE cost 4.117199620703752e+100|Validation cost 2.5451477902086682e+101\n",
            "Epochs 90/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 3.063186262362109e+202\n",
            "MAE cost 5.17380712984769e+101|Validation cost 3.1983156020127294e+102\n",
            "Epochs 91/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 4.8371552607460304e+204\n",
            "MAE cost 6.501574536793359e+102|Validation cost 4.0191075463006365e+103\n",
            "Epochs 92/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 7.638474781654342e+206\n",
            "MAE cost 8.170090302288515e+103|Validation cost 5.0505414345492824e+104\n",
            "Epochs 93/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 1.2062109617083212e+209\n",
            "MAE cost 1.0266801552423758e+105|Validation cost 6.34667484963864e+105\n",
            "Epochs 94/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 1.9047583787796463e+211\n",
            "MAE cost 1.290159719376974e+106|Validation cost 7.97543831073041e+106\n",
            "Epochs 95/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 3.007852354776222e+213\n",
            "MAE cost 1.621256720511871e+107|Validation cost 1.002219552052331e+108\n",
            "Epochs 96/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 4.7497760812735055e+215\n",
            "MAE cost 2.0373239951052048e+108|Validation cost 1.2594217287902078e+109\n",
            "Epochs 97/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 7.500492099093189e+217\n",
            "MAE cost 2.5601676825869726e+109|Validation cost 1.582630360484222e+110\n",
            "Epochs 98/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 1.1844217656988095e+220\n",
            "MAE cost 3.217190087934093e+110|Validation cost 1.9887848531344896e+111\n",
            "Epochs 99/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200]|Validation cost 1.87035050570974e+222\n",
            "MAE cost 4.0428258400022834e+111|Validation cost 2.4991718159931047e+112\n",
            "Epochs 100/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 2.953518008126718e+224\n",
            "MAE cost 5.08034661485784e+112|Validation cost 3.140540695495682e+113\n",
            "Epochs 101/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 4.663975333873908e+226\n",
            "MAE cost 6.384129009891491e+113|Validation cost 3.9465057171930425e+114\n",
            "Epochs 102/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 7.365001958725476e+228\n",
            "MAE cost 8.022504428288619e+114|Validation cost 4.959307611640146e+115\n",
            "Epochs 103/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 1.1630261733604734e+231\n",
            "MAE cost 1.0081340336667854e+116|Validation cost 6.232027456522961e+116\n",
            "Epochs 104/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 1.836564182198238e+233\n",
            "MAE cost 1.2668540590061981e+117|Validation cost 7.831368662774174e+117\n",
            "Epochs 105/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 2.9001651661781184e+235\n",
            "MAE cost 1.5919700686852787e+118|Validation cost 9.841152908928194e+118\n",
            "Epochs 106/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 4.579724505486996e+237\n",
            "MAE cost 2.000521434629915e+119|Validation cost 1.2366713246085196e+120\n",
            "Epochs 107/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 7.2319593348532635e+239\n",
            "MAE cost 2.513920386530155e+120|Validation cost 1.5540414616680854e+121\n",
            "Epochs 108/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 1.1420170745709447e+242\n",
            "MAE cost 3.159074229555081e+121|Validation cost 1.9528591118161375e+122\n",
            "Epochs 109/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222]|Validation cost 1.80338818047024e+244\n",
            "MAE cost 3.969795559681031e+122|Validation cost 2.4540263594446103e+123\n",
            "Epochs 110/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 2.847776098865785e+246\n",
            "MAE cost 4.9885743862000797e+123|Validation cost 3.083809444526875e+124\n",
            "Epochs 111/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 4.496995598117185e+248\n",
            "MAE cost 6.268805038577617e+124|Validation cost 3.8752153796365106e+125\n",
            "Epochs 112/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 7.101320015130322e+250\n",
            "MAE cost 7.877584570134139e+125|Validation cost 4.869721851725938e+126\n",
            "Epochs 113/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 1.1213874876462894e+253\n",
            "MAE cost 9.899229323248495e+126|Validation cost 6.119451073039831e+127\n",
            "Epochs 114/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 1.7708114755712486e+255\n",
            "MAE cost 1.2439693959717684e+128|Validation cost 7.689901512969586e+128\n",
            "Epochs 115/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 2.7963333964039333e+257\n",
            "MAE cost 1.563212455822326e+129|Validation cost 9.663380681267031e+129\n",
            "Epochs 116/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 4.415761119529372e+259\n",
            "MAE cost 1.9643836817457563e+130|Validation cost 1.21433188752276e+131\n",
            "Epochs 117/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 6.97304058586963e+261\n",
            "MAE cost 2.4685085093434047e+131|Validation cost 1.5259689974888216e+132\n",
            "Epochs 118/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 1.101130557020877e+264\n",
            "MAE cost 3.102008185735613e+132|Validation cost 1.9175823390814104e+133\n",
            "Epochs 119/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244]|Validation cost 1.7388232417033802e+266\n",
            "MAE cost 3.898084510525028e+133|Validation cost 2.4096964179535185e+134\n",
            "Epochs 120/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 2.7458199635000454e+268\n",
            "MAE cost 4.8984599463884954e+134|Validation cost 3.028102996338399e+135\n",
            "Epochs 121/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 4.335994074112762e+270\n",
            "MAE cost 6.155564298717716e+135|Validation cost 3.8052128426289027e+136\n",
            "Epochs 122/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 6.847078417616242e+272\n",
            "MAE cost 7.735282568470143e+136|Validation cost 4.781754383921819e+137\n",
            "Epochs 123/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 1.0812395509691578e+275\n",
            "MAE cost 9.720407993551846e+137|Validation cost 6.008908288125795e+138\n",
            "Epochs 124/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 1.7074128486277689e+277\n",
            "MAE cost 1.2214981253075775e+139|Validation cost 7.550989849355931e+139\n",
            "Epochs 125/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 2.696219013673825e+279\n",
            "MAE cost 1.5349743252749279e+140|Validation cost 9.48881976077892e+140\n",
            "Epochs 126/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 4.257667953909775e+281\n",
            "MAE cost 1.9288987272575096e+141|Validation cost 1.1923959937547583e+142\n",
            "Epochs 127/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 6.723391650980791e+283\n",
            "MAE cost 2.4239169598809016e+142|Validation cost 1.4984036389850063e+143\n",
            "Epochs 128/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 1.0617078593685966e+286\n",
            "MAE cost 3.0459729924503723e+143|Validation cost 1.8829428118535643e+144\n",
            "Epochs 129/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266]|Validation cost 1.6765698581319606e+288\n",
            "MAE cost 3.827668861722452e+144|Validation cost 2.366167259919798e+145\n",
            "Epochs 130/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 2.647514063678754e+290\n",
            "MAE cost 4.809973348848844e+145|Validation cost 2.9734028387218897e+146\n",
            "Epochs 131/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 4.180756729807014e+292\n",
            "MAE cost 6.044369158471307e+146|Validation cost 3.7364748431262905e+147\n",
            "Epochs 132/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 6.601939182728923e+294\n",
            "MAE cost 7.595551133900315e+147|Validation cost 4.6953759751291706e+148\n",
            "Epochs 133/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 1.0425289915030136e+297\n",
            "MAE cost 9.544816922182407e+148|Validation cost 5.900362366517089e+149\n",
            "Epochs 134/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 1.6462840205611111e+299\n",
            "MAE cost 1.1994327794248942e+150|Validation cost 7.414587509204394e+150\n",
            "Epochs 135/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 2.5996889280244282e+301\n",
            "MAE cost 1.5072462930278865e+151|Validation cost 9.317412137875447e+151\n",
            "Epochs 136/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 4.105234842885316e+303\n",
            "MAE cost 1.8940547789060652e+152|Validation cost 1.170856353630711e+153\n",
            "Epochs 137/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost 6.482680652121955e+305\n",
            "MAE cost 2.380130919605805e+153|Validation cost 1.471336225715134e+154\n",
            "Epochs 138/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost inf\n",
            "MAE cost 2.9909500282433634e+154|Validation cost 1.8489290188234698e+155\n",
            "Epochs 139/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288]|Validation cost inf\n",
            "MAE cost 3.758525212945248e+155|Validation cost 2.323424419857507e+156\n",
            "Epochs 140/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 4.723085187966803e+156|Validation cost 2.919690793876607e+157\n",
            "Epochs 141/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 5.935182665785772e+157|Validation cost 3.6689785383122625e+158\n",
            "Epochs 142/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 7.458343831271904e+158|Validation cost 4.61055792032096e+159\n",
            "Epochs 143/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 9.372397757214956e+159|Validation cost 5.793777236541895e+160\n",
            "Epochs 144/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 1.1777660256307586e+161|Validation cost 7.280649163677406e+161\n",
            "Epochs 145/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 1.4800191445804199e+162|Validation cost 9.149100850863066e+162\n",
            "Epochs 146/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 1.859840257449647e+163|Validation cost 1.1497058091586976e+164\n",
            "Epochs 147/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 2.337135837665793e+164|Validation cost 1.4447577627134406e+165\n",
            "Epochs 148/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 2.9369210080396765e+165|Validation cost 1.8155296566242067e+166\n",
            "Epochs 149/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf]|Validation cost inf\n",
            "MAE cost 3.690630586572787e+166|Validation cost 2.2814536935876508e+167\n",
            "Epochs 150/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 4.637766589315971e+167|Validation cost 2.866949012368634e+168\n",
            "Epochs 151/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 5.8279685361165305e+168|Validation cost 3.602701498006849e+169\n",
            "Epochs 152/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 7.323615064244494e+169|Validation cost 4.527272033002546e+170\n",
            "Epochs 153/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 9.203093200803177e+170|Validation cost 5.689117478133085e+171\n",
            "Epochs 154/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 1.1564906636911971e+172|Validation cost 7.149130302765074e+172\n",
            "Epochs 155/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 1.4532838318840252e+173|Validation cost 8.983829967013777e+173\n",
            "Epochs 156/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 1.826243792815836e+174|Validation cost 1.1289373316499601e+175\n",
            "Epochs 157/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 2.2949174260575705e+175|Validation cost 1.418659417500725e+176\n",
            "Epochs 158/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 2.883867977069045e+176|Validation cost 1.7827336260747585e+177\n",
            "Epochs 159/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf]|Validation cost inf\n",
            "MAE cost 3.6239624200560105e+177|Validation cost 2.240241133517893e+178\n",
            "Epochs 160/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.553989200062395e+178|Validation cost 2.815159967199203e+179\n",
            "Epochs 161/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.722691140369055e+179|Validation cost 3.537621697212586e+180\n",
            "Epochs 162/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.1913200601375555e+180|Validation cost 4.445490635844819e+181\n",
            "Epochs 163/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.03684699013858e+181|Validation cost 5.586348311057518e+182\n",
            "Epochs 164/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.1355996234384627e+183|Validation cost 7.019987220493736e+183\n",
            "Epochs 165/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.4270314703356535e+184|Validation cost 8.821544563977681e+184\n",
            "Epochs 166/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.793254220323092e+185|Validation cost 1.1085440193831422e+186\n",
            "Epochs 167/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.2534616548787104e+186|Validation cost 1.393032517149161e+187\n",
            "Epochs 168/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.8317733048991634e+187|Validation cost 1.7505300284915658e+188\n",
            "Epochs 169/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.558498558419509e+188|Validation cost 2.1997730440075316e+189\n",
            "Epochs 170/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.471725179542447e+189|Validation cost 2.7643064479801772e+190\n",
            "Epochs 171/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.619315493058739e+190|Validation cost 3.473717508795249e+191\n",
            "Epochs 172/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.061414855051747e+191|Validation cost 4.365186551486568e+192\n",
            "Epochs 173/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.873603878753467e+192|Validation cost 5.485435583358008e+193\n",
            "Epochs 174/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.1150859624215008e+194|Validation cost 6.893177000401747e+194\n",
            "Epochs 175/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.401253335825213e+195|Validation cost 8.662190711531403e+195\n",
            "Epochs 176/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.760860576970552e+196|Validation cost 1.0885190953107377e+197\n",
            "Epochs 177/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.2127547476652905e+197|Validation cost 1.3678685454001407e+198\n",
            "Epochs 178/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.7806196795768045e+198|Validation cost 1.7189081620667095e+199\n",
            "Epochs 179/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.494217246899049e+199|Validation cost 2.160035976816204e+200\n",
            "Epochs 180/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.390947190010897e+200|Validation cost 2.7143715552147437e+201\n",
            "Epochs 181/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.517807240684603e+201|Validation cost 3.4109676962967678e+202\n",
            "Epochs 182/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.933856279258932e+202|Validation cost 4.28633309350297e+203\n",
            "Epochs 183/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.713309618161538e+203|Validation cost 5.386345760004009e+204\n",
            "Epochs 184/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.0949428635988492e+205|Validation cost 6.768657501277572e+205\n",
            "Epochs 185/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.3759408618363885e+206|Validation cost 8.505715453656102e+206\n",
            "Epochs 186/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.7290520977948257e+207|Validation cost 1.0688559048069554e+208\n",
            "Epochs 187/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.172783176813728e+208|Validation cost 1.3431591398341717e+209\n",
            "Epochs 188/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.7303901018747453e+209|Validation cost 1.687857518311511e+210\n",
            "Epochs 189/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.4310971237120824e+210|Validation cost 2.121016726634803e+211\n",
            "Epochs 190/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.311628387556093e+211|Validation cost 2.6653386946814145e+212\n",
            "Epochs 191/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.418132650313028e+212|Validation cost 3.34935140687799e+213\n",
            "Epochs 192/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.808601942856133e+213|Validation cost 4.208904057537222e+214\n",
            "Epochs 193/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.555910939830179e+214|Validation cost 5.289045911747358e+215\n",
            "Epochs 194/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.0751636330732187e+216|Validation cost 6.646387343155553e+216\n",
            "Epochs 195/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.351085636599844e+217|Validation cost 8.352066790939291e+217\n",
            "Epochs 196/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.6978182122926155e+218|Validation cost 1.0495479134562729e+219\n",
            "Epochs 197/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.133533659085326e+219|Validation cost 1.3188960890918997e+220\n",
            "Epochs 198/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.681067879642641e+220|Validation cost 1.6573677785643853e+221\n",
            "Epochs 199/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.369117212958866e+221|Validation cost 2.0827023266971303e+222\n",
            "Epochs 200/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.2337424131792905e+222|Validation cost 2.617191571919491e+223\n",
            "Epochs 201/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.32025859836775e+223|Validation cost 3.2888481643889334e+224\n",
            "Epochs 202/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.685610221678669e+224|Validation cost 4.132873712592403e+225\n",
            "Epochs 203/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.401355537478463e+225|Validation cost 5.193503704179331e+226\n",
            "Epochs 204/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.0557416978669991e+227|Validation cost 6.526325893564638e+227\n",
            "Epochs 205/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.3266794002978491e+228|Validation cost 8.201193663294547e+228\n",
            "Epochs 206/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.667148540907961e+229|Validation cost 1.0305887048819423e+230\n",
            "Epochs 207/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.0949931511920294e+230|Validation cost 1.2950713301453376e+231\n",
            "Epochs 208/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.6326366222599326e+231|Validation cost 1.6274288105617702e+232\n",
            "Epochs 209/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.308256917651805e+232|Validation cost 2.04508004447081e+233\n",
            "Epochs 210/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.157263384035086e+233|Validation cost 2.5699141868141263e+234\n",
            "Epochs 211/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.224152559622299e+234|Validation cost 3.229437862564198e+235\n",
            "Epochs 212/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.564840243467693e+235|Validation cost 4.058216792480603e+236\n",
            "Epochs 213/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.249592049694818e+236|Validation cost 5.0996873869853445e+237\n",
            "Epochs 214/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.0366706037379428e+238|Validation cost 6.408433254025504e+238\n",
            "Epochs 215/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.3027140423193982e+239|Validation cost 8.053045932993367e+239\n",
            "Epochs 216/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.6370328915829307e+240|Validation cost 1.0119719786137125e+241\n",
            "Epochs 217/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.0571488454619128e+241|Validation cost 1.2716769456183802e+242\n",
            "Epochs 218/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.585080235188969e+242|Validation cost 1.5980306650710059e+243\n",
            "Epochs 219/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.2484960128707334e+243|Validation cost 2.008137377426064e+244\n",
            "Epochs 220/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.082165884830127e+244|Validation cost 2.523490828279222e+245\n",
            "Epochs 221/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.129782596391336e+245|Validation cost 3.171100758341328e+246\n",
            "Epochs 222/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.446251874287682e+246|Validation cost 3.9849084874265556e+247\n",
            "Epochs 223/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 8.10057004286881e+247|Validation cost 5.007565783393812e+248\n",
            "Epochs 224/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.0179440130343123e+249|Validation cost 6.292670246791618e+249\n",
            "Epochs 225/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.2791815985649169e+250|Validation cost 7.907574368003542e+250\n",
            "Epochs 226/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.6074612563706295e+251|Validation cost 9.936915479940818e+251\n",
            "Epochs 227/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.0199881655829744e+252|Validation cost 1.2487051611557252e+253\n",
            "Epochs 228/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.5383829146265093e+253|Validation cost 1.569163572584027e+254\n",
            "Epochs 229/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.1898146390418053e+254|Validation cost 1.9718620488808872e+255\n",
            "Epochs 230/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.0084249593771445e+255|Validation cost 2.4779060690363567e+256\n",
            "Epochs 231/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.037117347917182e+256|Validation cost 3.113817465299826e+257\n",
            "Epochs 232/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.329805705189196e+257|Validation cost 3.912924435822903e+258\n",
            "Epochs 233/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.954239994431126e+258|Validation cost 4.917108279815533e+259\n",
            "Epochs 234/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.995557025887663e+259|Validation cost 6.178998401829793e+260\n",
            "Epochs 235/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.2560742487996517e+261|Validation cost 7.764730625628499e+261\n",
            "Epochs 236/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.5784238081093824e+262|Validation cost 9.757413381223586e+262\n",
            "Epochs 237/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.9834987624238082e+263|Validation cost 1.2261483428393203e+264\n",
            "Epochs 238/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.492529142251851e+264|Validation cost 1.5408179400707933e+265\n",
            "Epochs 239/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.1321932953378365e+265|Validation cost 1.9362420039213127e+266\n",
            "Epochs 240/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.9360161023016053e+266|Validation cost 2.433144760488037e+267\n",
            "Epochs 241/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.94612601994812e+267|Validation cost 3.0575689472187366e+268\n",
            "Epochs 242/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.2154630391126434e+268|Validation cost 3.842240716134433e+269\n",
            "Epochs 243/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.810553276396422e+269|Validation cost 4.8282848156702955e+270\n",
            "Epochs 244/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.814995616502978e+270|Validation cost 6.0673799440359395e+271\n",
            "Epochs 245/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.2333843140548763e+272|Validation cost 7.624467236442203e+272\n",
            "Epochs 246/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.5499108971570023e+273|Validation cost 9.581153838358713e+273\n",
            "Epochs 247/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.947668509929779e+274|Validation cost 1.2039989946514834e+275\n",
            "Epochs 248/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.447503680069824e+275|Validation cost 1.512984347791359e+276\n",
            "Epochs 249/500: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in square\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.0756128331978345e+276|Validation cost 1.901265405395348e+277\n",
            "Epochs 250/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.864915250898151e+277|Validation cost 2.3891920276835678e+278\n",
            "Epochs 251/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.8567783745049417e+278|Validation cost 3.0023365117505773e+279\n",
            "Epochs 252/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 6.103185878028575e+279|Validation cost 3.772833838948533e+280\n",
            "Epochs 253/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.669462139203388e+280|Validation cost 4.7410658733972226e+281\n",
            "Epochs 254/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.637695898535243e+281|Validation cost 5.957777780681745e+282\n",
            "Epochs 255/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.2111042540760342e+283|Validation cost 7.486737588514241e+283\n",
            "Epochs 256/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.5219130481840482e+284|Validation cost 9.40807827727642e+284\n",
            "Epochs 257/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.9124855010933243e+285|Validation cost 1.1822497559838456e+286\n",
            "Epochs 258/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.4032915653469464e+286|Validation cost 1.4856535461655318e+287\n",
            "Epochs 259/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.0200544499636084e+287|Validation cost 1.8669206299792877e+288\n",
            "Epochs 260/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.7950987771341417e+288|Validation cost 2.346033264375837e+289\n",
            "Epochs 261/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.769044719832323e+289|Validation cost 2.9481018042095373e+290\n",
            "Epochs 262/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.99293691031027e+290|Validation cost 3.7046807391692535e+291\n",
            "Epochs 263/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.530919695846752e+291|Validation cost 4.655422468645577e+292\n",
            "Epochs 264/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.463598952246648e+292|Validation cost 5.850155489088132e+293\n",
            "Epochs 265/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.1892266648169863e+294|Validation cost 7.351495911919895e+294\n",
            "Epochs 266/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.494420957025011e+295|Validation cost 9.238129181998699e+295\n",
            "Epochs 267/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.8779380439970526e+296|Validation cost 1.1608933991912947e+297\n",
            "Epochs 268/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.359878105639048e+297|Validation cost 1.4588164526990787e+298\n",
            "Epochs 269/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 2.96549968263132e+298|Validation cost 1.8331962643150866e+299\n",
            "Epochs 270/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 3.7265434797976654e+299|Validation cost 2.303654128167424e+300\n",
            "Epochs 271/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 4.6828959005317766e+300|Validation cost 2.8948468014719254e+301\n",
            "Epochs 272/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 5.88467949833447e+301|Validation cost 3.637758768352396e+302\n",
            "Epochs 273/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 7.394879906295931e+302|Validation cost 4.5713261406427733e+303\n",
            "Epochs 274/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 9.292646922235359e+303|Validation cost 5.744477304521372e+304\n",
            "Epochs 275/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.167744275979518e+305|Validation cost 7.218697263529998e+305\n",
            "Epochs 276/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.4674254875863794e+306|Validation cost 9.071250075525754e+306\n",
            "Epochs 277/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost 1.8440146579283187e+307|Validation cost 1.1399228271901064e+308\n",
            "Epochs 278/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost inf\n",
            "MAE cost inf|Validation cost inf\n",
            "Epochs 279/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]|Validation cost nan\n",
            "MAE cost inf|Validation cost nan\n",
            "Epochs 280/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 281/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 282/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 283/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 284/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 285/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 286/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 287/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 288/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 289/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 290/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 291/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 292/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 293/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 294/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 295/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 296/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 297/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 298/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 299/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 300/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 301/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 302/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 303/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 304/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 305/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 306/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 307/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 308/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 309/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 310/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 311/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 312/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 313/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 314/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 315/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 316/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 317/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 318/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 319/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 320/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 321/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 322/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 323/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 324/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 325/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 326/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 327/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 328/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 329/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 330/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 331/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 332/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 333/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 334/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 335/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 336/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 337/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 338/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 339/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 340/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 341/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 342/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 343/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 344/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 345/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 346/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 347/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 348/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 349/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 350/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 351/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 352/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 353/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 354/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 355/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epochs 356/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 357/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 358/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 359/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 360/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 361/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 362/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 363/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 364/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 365/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 366/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 367/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 368/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 369/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 370/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 371/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 372/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 373/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 374/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 375/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 376/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 377/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 378/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 379/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 380/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 381/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 382/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 383/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 384/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 385/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 386/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 387/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 388/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 389/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 390/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 391/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 392/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 393/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 394/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 395/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 396/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 397/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 398/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 399/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 400/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 401/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 402/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 403/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 404/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 405/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 406/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 407/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 408/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 409/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 410/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 411/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 412/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 413/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 414/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 415/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 416/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 417/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 418/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 419/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 420/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 421/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 422/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 423/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 424/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 425/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 426/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 427/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 428/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 429/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 430/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 431/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 432/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 433/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 434/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 435/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 436/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 437/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 438/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 439/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 440/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 441/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 442/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 443/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 444/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 445/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 446/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 447/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 448/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 449/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 450/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 451/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 452/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 453/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 454/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 455/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 456/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 457/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 458/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 459/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 460/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 461/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 462/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 463/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 464/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 465/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 466/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 467/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 468/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 469/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 470/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 471/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 472/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 473/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 474/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 475/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 476/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 477/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 478/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 479/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 480/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 481/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 482/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 483/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 484/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 485/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 486/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 487/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 488/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 489/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 490/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 491/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 492/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 493/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 494/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 495/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 496/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 497/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 498/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 499/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n",
            "Epochs 500/500: \n",
            "Training cost [5.286062074299099e+24, 5.096810374108415e+46, 4.914334269809669e+68, 4.738391178551618e+90, 4.568747205274133e+112, 4.405176828832566e+134, 4.247462602194676e+156, 4.095394863371118e+178, 3.948771456695169e+200, 3.8073974640812317e+222, 3.6710849459048007e+244, 3.539652691159469e+266, 3.4129259765587983e+288, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]|Validation cost nan\n",
            "MAE cost nan|Validation cost nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}